{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3844296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2375903",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1dd4b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>pm2.5_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41757.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.750174</td>\n",
       "      <td>12.401561</td>\n",
       "      <td>1016.442896</td>\n",
       "      <td>23.866747</td>\n",
       "      <td>0.055344</td>\n",
       "      <td>0.194866</td>\n",
       "      <td>98.613215</td>\n",
       "      <td>98.613215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.433658</td>\n",
       "      <td>12.175215</td>\n",
       "      <td>10.300733</td>\n",
       "      <td>49.617495</td>\n",
       "      <td>0.778875</td>\n",
       "      <td>1.418165</td>\n",
       "      <td>92.050387</td>\n",
       "      <td>92.050387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>565.490000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>994.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DEWP          TEMP          PRES           Iws            Is  \\\n",
       "count  41757.000000  41757.000000  41757.000000  41757.000000  41757.000000   \n",
       "mean       1.750174     12.401561   1016.442896     23.866747      0.055344   \n",
       "std       14.433658     12.175215     10.300733     49.617495      0.778875   \n",
       "min      -40.000000    -19.000000    991.000000      0.450000      0.000000   \n",
       "25%      -10.000000      2.000000   1008.000000      1.790000      0.000000   \n",
       "50%        2.000000     14.000000   1016.000000      5.370000      0.000000   \n",
       "75%       15.000000     23.000000   1025.000000     21.910000      0.000000   \n",
       "max       28.000000     42.000000   1046.000000    565.490000     27.000000   \n",
       "\n",
       "                 Ir         pm2.5     pm2.5_pre  \n",
       "count  41757.000000  41757.000000  41757.000000  \n",
       "mean       0.194866     98.613215     98.613215  \n",
       "std        1.418165     92.050387     92.050387  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000     29.000000     29.000000  \n",
       "50%        0.000000     72.000000     72.000000  \n",
       "75%        0.000000    137.000000    137.000000  \n",
       "max       36.000000    994.000000    994.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#### Loading the data\"\"\"\n",
    "\n",
    "orig_data = pd.read_csv('./Data/UCI-PM.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "orig_data = orig_data.drop(columns=['cbwd', 'No'])\n",
    "\n",
    "# Drop na values\n",
    "aug_data = orig_data.dropna()\n",
    "aug_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c4b11",
   "metadata": {},
   "source": [
    "#### Normalize and function to inverse transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb72bc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#### Scaling and inverse_transform method\"\"\"\n",
    "\n",
    "# Scale the whole data\n",
    "temp_x = aug_data.values # Returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "temp_x_scaled = min_max_scaler.fit_transform(temp_x)\n",
    "df = pd.DataFrame(temp_x_scaled, columns = aug_data.columns)\n",
    "\n",
    "# Inverse_transform of PM2.5\n",
    "pm_inv_scaler = preprocessing.MinMaxScaler()\n",
    "temp_scaler = np.reshape(aug_data['pm2.5'].values, (-1,1))\n",
    "pm_inv_scaler.fit(temp_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eba44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pm_scaler(data):\n",
    "    data = np.asarray(data)\n",
    "    data = np.reshape(data, (-1, 1))\n",
    "    return pm_inv_scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339b59e",
   "metadata": {},
   "source": [
    "#### Model Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d430680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save the generated files locally\n",
    "path = \"./msvlstm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e7e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to supervised learning format\n",
    "def convert_to_supervised(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        \n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        \n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ed3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and train\n",
    "def split_data(x, y, split_percentage = 0.8):\n",
    "    n_train_hours = (int)(split_percentage * len(x))\n",
    "\n",
    "    train_x = x[:n_train_hours, :]\n",
    "    train_y = y[:n_train_hours]\n",
    "\n",
    "    test_x  = x[n_train_hours:, :]\n",
    "    test_y = y[n_train_hours:]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de1095",
   "metadata": {},
   "source": [
    "#### Compute Error matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e5549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_metric(actual, predicted):\n",
    "    rmse = []\n",
    "    for i in range(len(actual[1])):\n",
    "        c_actual = inverse_pm_scaler(actual[:, i])\n",
    "        c_predicted = inverse_pm_scaler(predicted[:, i])\n",
    "        sum_error = 0.0\n",
    "        for j in range(len(c_actual)):\n",
    "            prediction_error = c_predicted[j] - c_actual[j]\n",
    "            sum_error += (prediction_error ** 2)\n",
    "        mean_error = sum_error / float(len(c_actual))\n",
    "        rmse.append(sqrt(mean_error))\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00af1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_function(actual, predicted):\n",
    "    mape = []\n",
    "    for i in range(len(actual[1])):\n",
    "        c_actual = inverse_pm_scaler(actual[:, i])\n",
    "        c_predicted = inverse_pm_scaler(predicted[:, i])\n",
    "        sum_error = 0.0\n",
    "\n",
    "        for j in range(len(c_actual)):\n",
    "            # Avoiding divide by zero\n",
    "            if c_actual[j] == 0:\n",
    "                c_actual[j] = 1\n",
    "            prediction_error = np.abs((c_actual[j] - c_predicted[j])/c_actual[j])\n",
    "            sum_error += prediction_error\n",
    "        \n",
    "        mape_error = sum_error / float(len(c_actual))*100\n",
    "        mape.append(mape_error[0])\n",
    "    \n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8b8cc",
   "metadata": {},
   "source": [
    "#### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10f65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_lstm(x, y, step, nodes, epoch, n_features=7):\n",
    "    model_id = \"msvlstm_\" + str(step) + \"_\" + str(nodes) + \"_\" + str(epoch) + '/'\n",
    "\n",
    "    # define model\n",
    "    base_model = Sequential()\n",
    "    base_model.add(LSTM(nodes, activation='relu', return_sequences=True, input_shape=(step, n_features)))\n",
    "    base_model.add(LSTM(nodes, activation='relu'))\n",
    "    base_model.add(Dense(6))  # Forecasting 6 steps in ahead.\n",
    "    base_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Tensorboard\n",
    "    v_log_dir = path + \"tb_vlstm/\" + model_id + \"/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    vlstm_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=v_log_dir, histogram_freq=1)\n",
    "\n",
    "    # fit base model\n",
    "    history = base_model.fit(x, y, callbacks=[vlstm_tensorboard_callback], validation_split=0.2, epochs=epoch, verbose=0)\n",
    "\n",
    "    return base_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace3f91",
   "metadata": {},
   "source": [
    "#### Grid-Search Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vlstm():\n",
    "    # choose a number of time steps\n",
    "    steps_out = 6\n",
    "\n",
    "    steps_in = [2, 4, 6, 12, 24]\n",
    "    epochs = [100]\n",
    "    n_nodes = [32, 64, 128, 256]\n",
    "\n",
    "    temp = []\n",
    "        for step in steps_in:\n",
    "            x, y = convert_to_supervised(df.values, step, steps_out)\n",
    "            train_x, train_y, test_x, test_y = split_data(x, y)\n",
    "\n",
    "        for epoch in epochs:\n",
    "            for nodes in n_nodes:\n",
    "                model_name = \"msvlstm_\" + str(step) + \"_\" + str(nodes) + \"_\" + str(epoch)\n",
    "\n",
    "                # Call method to fit the model\n",
    "                v_model, history = vanilla_lstm(train_x, train_y, step, nodes, epoch)\n",
    "\n",
    "                # Calculate Train RMSE\n",
    "                train_yhat = v_model.predict(train_x, verbose=0)\n",
    "\n",
    "                train_rmse = rmse_metric(train_y, train_yhat)\n",
    "                train_mape = mape_function(train_y, train_yhat)\n",
    "\n",
    "                # Calculate Test RMSE\n",
    "                test_yhat = v_model.predict(test_x, verbose=0)\n",
    "\n",
    "                test_rmse = rmse_metric(test_y, test_yhat)\n",
    "                test_mape = mape_function(train_y, train_yhat)\n",
    "\n",
    "                temp.append([step, nodes, epoch, train_rmse, train_mape, test_rmse, train_mape])\n",
    "\n",
    "                # Save all the data locally\n",
    "                os.makedirs(os.path.dirname(path + 'train_y/'), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(path + 'train_yhat/'), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(path + 'test_y/'), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(path + 'test_yhat/'), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(path + 'history/'), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(path + 'model/'), exist_ok=True)\n",
    "\n",
    "                np.save(path + 'train_y/' + model_name, test_y)\n",
    "                np.save(path + 'train_yhat/' + model_name, test_yhat)\n",
    "                np.save(path + 'test_y/' + model_name, test_y)\n",
    "                np.save(path + 'test_yhat/' + model_name, test_yhat)\n",
    "                np.save(path + 'history/' + model_name, history.history)\n",
    "                v_model.save(path + 'model/' + model_name + '.h5')\n",
    "\n",
    "    temp_df = pd.DataFrame(temp, columns=['Step Size', 'No of Nodes', 'Epoch', 'Train RMSE', 'Train MAPE', 'Test RMSE', 'Train MAPE'])\n",
    "    temp_df.to_csv(path + 'msvanilla.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa0bbc",
   "metadata": {},
   "source": [
    "### Call the grid-search method and train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcaf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model will take quite a long time based on system configuration.\n",
    "grid_vlstm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
